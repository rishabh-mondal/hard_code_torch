{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Bernoulli\n",
    "from torch.optim import Adam\n",
    "from torch.distributions import Beta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bernoulli(probs: tensor([0.6000]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=0.6\n",
    "dist=Bernoulli(torch.tensor([p]))\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "sample=dist.sample()\n",
    "print(\"Sample:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: tensor([0.6000])\n",
      "tensor([-0.5108])\n"
     ]
    }
   ],
   "source": [
    "prob = (p ** sample) * ((1 - p) ** (1 - sample))\n",
    "print(\"Probability:\", prob)\n",
    "log_prob=dist.log_prob(sample)\n",
    "print(log_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log(P(x; p)) = x * log(p) + (1 - x) * log(1 - p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0.0 Prob: 0.3999999761581421\n",
      "Sample: 0.0 Log Prob: 0.4\n",
      "Sample: 0.0 Prob: 0.3999999761581421\n",
      "Sample: 0.0 Log Prob: 0.4\n",
      "Sample: 1.0 Prob: 0.6000000834465027\n",
      "Sample: 1.0 Log Prob: 0.6\n",
      "Sample: 1.0 Prob: 0.6000000834465027\n",
      "Sample: 1.0 Log Prob: 0.6\n",
      "Sample: 0.0 Prob: 0.3999999761581421\n",
      "Sample: 0.0 Log Prob: 0.4\n",
      "Sample: 1.0 Prob: 0.6000000834465027\n",
      "Sample: 1.0 Log Prob: 0.6\n",
      "Sample: 1.0 Prob: 0.6000000834465027\n",
      "Sample: 1.0 Log Prob: 0.6\n",
      "Sample: 0.0 Prob: 0.3999999761581421\n",
      "Sample: 0.0 Log Prob: 0.4\n",
      "Sample: 1.0 Prob: 0.6000000834465027\n",
      "Sample: 1.0 Log Prob: 0.6\n",
      "Sample: 1.0 Prob: 0.6000000834465027\n",
      "Sample: 1.0 Log Prob: 0.6\n"
     ]
    }
   ],
   "source": [
    "size = 10\n",
    "dataset = dist.sample(torch.Size([size]))\n",
    "probs = dist.log_prob(dataset).exp()\n",
    "for i in range(size):\n",
    "    sample = dataset[i].item()\n",
    "    print(\"Sample:\", sample, \"Prob:\", probs[i].item())\n",
    "    print(\"Sample:\", sample, \"Log Prob:\", (p ** sample) * ((1 - p) ** (1 - sample)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Likelihood Estimations of Bernoulli Distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLE = (number of successes) / (total number of observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE Estimate: 0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "dataset\n",
    "num_suc=dataset.float().sum()\n",
    "p_estimate=num_suc.float()/dataset.size(0)\n",
    "print(\"MLE Estimate:\", p_estimate.item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum Likelihood Estimate by Automatic Differentiation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLL(p; x) = -[x * log(p) + (1 - x) * log(1 - p)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE Estimate  0.6003569960594177\n"
     ]
    }
   ],
   "source": [
    "p = torch.tensor(0.5, requires_grad=True)\n",
    "def negative_log_likelihood(p):\n",
    "    return -(dataset * torch.log(p) + (1 - dataset) * torch.log(1 - p)).mean()\n",
    "\n",
    "optimizer = Adam([p], lr=0.1)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    loss=negative_log_likelihood(p)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "mle_estimate=p.item()\n",
    "print(\"MLE Estimate \", mle_estimate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Distrubution : f(x; α, β) = (1/B(α, β)) * x^(α-1) * (1-x)^(β-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 0.3387662470340729\n",
      "Log Probability: 0.664161205291748\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha = torch.tensor(2.0)\n",
    "beta = torch.tensor(5.0)\n",
    "#beta_dist = dist.Beta(alpha, beta)\n",
    "sample = beta_dist.sample()\n",
    "print(\"Sample:\", sample.item())\n",
    "log_prob = beta_dist.log_prob(sample)\n",
    "print(\"Log Probability:\", log_prob.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940b4261e8ea4b0f8b20c42bd039c16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=0.5, description='Alpha:', max=10.0, min=0.1), FloatSlider(value=0.5, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "x\n",
    "def plot(alpha, beta):\n",
    "    pdf = stats.beta.pdf(x, alpha, beta)\n",
    "    if np.any(np.isnan(pdf)) or np.any(np.isinf(pdf)):\n",
    "        print(\"Invalid parameter values. Please choose different values.\")\n",
    "        return\n",
    "    plt.clf()\n",
    "    plt.plot(x, pdf)\n",
    "    plt.title(f\"Alpha = {alpha:.1f}, Beta = {beta:.1f}\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('PDF')\n",
    "    plt.ylim(0, np.max(pdf) * 1.1)\n",
    "    plt.show()\n",
    "alpha_slider = widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=0.5, description='Alpha:')\n",
    "beta_slider = widgets.FloatSlider(min=0.1, max=10.0, step=0.1, value=0.5, description='Beta:')\n",
    "output = widgets.interactive_output(plot, {'alpha': alpha_slider, 'beta': beta_slider})\n",
    "display(widgets.VBox([alpha_slider, beta_slider, output]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior for the Bernoulli using the Conjugate Prior\n",
    "P(p∣k,n,α,β)=Beta(p∣α+k,β+n−k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.)\n",
      "tensor(4.)\n",
      "Sample from Posterior: 0.6189901828765869\n",
      "Log Probability from Posterior: 1.0571985244750977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_alpha = 2\n",
    "prior_beta = 2\n",
    "prior_dist = Beta(prior_alpha, prior_beta)\n",
    "n_ones = dataset.sum()\n",
    "print(n_ones)\n",
    "n_zeros = len(dataset) - n_ones\n",
    "print(n_zeros)\n",
    "posterior_alpha = prior_alpha + n_ones\n",
    "posterior_beta = prior_beta + n_zeros\n",
    "posterior_dist = Beta(posterior_alpha, posterior_beta)\n",
    "sample = posterior_dist.sample()\n",
    "print(\"Sample from Posterior:\", sample.item())\n",
    "log_prob = posterior_dist.log_prob(sample)\n",
    "print(\"Log Probability from Posterior:\", log_prob.item())\n",
    "posterior_alpha\n",
    "posterior_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2598350f51d47149a250c3d51e194c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=2.0, description='Alpha:', max=10.0), FloatSlider(value=2.0, description='Bet…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def update_plot(alpha, beta):\n",
    "    prior_dist = Beta(alpha, beta)\n",
    "    n_ones = dataset.sum()\n",
    "    n_zeros = len(dataset) - n_ones\n",
    "    posterior_alpha = alpha + n_ones\n",
    "    posterior_beta = beta + n_zeros\n",
    "    posterior_dist = Beta(posterior_alpha, posterior_beta)\n",
    "    log_pdf = posterior_dist.log_prob(torch.tensor(x))\n",
    "    pdf = torch.exp(log_pdf)\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    plt.plot(x, pdf)\n",
    "    plt.title(f\"Posterior Distribution (Alpha = {posterior_alpha}, Beta = {posterior_beta})\")\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('PDF')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "alpha_slider = widgets.FloatSlider(min=0, max=10, step=0.1, value=2.0, description='Alpha:')\n",
    "beta_slider = widgets.FloatSlider(min=0, max=10, step=0.1, value=2.0, description='Beta:')\n",
    "\n",
    "output = widgets.interactive_output(update_plot, {'alpha': alpha_slider, 'beta': beta_slider})\n",
    "\n",
    "display(widgets.VBox([alpha_slider, beta_slider, output]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAP Estimate = (Number of Successes + Prior Alpha) / (Total Observations + Prior Alpha + Prior Beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP Estimate: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "prior_alpha = 1.0\n",
    "prior_beta = 1.0\n",
    "total_observations = len(dataset)\n",
    "num_successes = dataset.sum().item()\n",
    "map_estimate = (num_successes + prior_alpha) / (total_observations + prior_alpha + prior_beta)\n",
    "print(\"MAP Estimate:\", map_estimate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP Estimate: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "prior_alpha = 1.0\n",
    "prior_beta = 1.0\n",
    "total_observations = len(dataset)\n",
    "num_successes = dataset.sum().item()\n",
    "map_estimate = (num_successes + prior_alpha) / (total_observations + prior_alpha + prior_beta)\n",
    "print(\"MAP Estimate:\", map_estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
